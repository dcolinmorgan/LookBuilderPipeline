{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline  # For using pre-trained models\n",
    "import numpy as np  # For numerical operations on arrays\n",
    "from PIL import Image  # For image manipulation\n",
    "from LookBuilderPipeline.resize.resize import resize_images\n",
    "import glob\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the segmentation model using a pre-trained model from Hugging Face\n",
    "segmenter = pipeline(model=\"mattmdjaga/segformer_b2_clothes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the image from the specified path\n",
    "# seg_img = Image.open(image_path)\n",
    "\n",
    "# Use the segmenter to get segments from the image\n",
    "\n",
    "\n",
    "image_folder=glob.glob(\"/Users/apple/WRK/modegen/MPI-cog/ComfyUI/input/jcrew_orig/*\") \n",
    "\n",
    "for j,i in enumerate(image_folder):\n",
    "    seg_img = Image.open(i)\n",
    "    \n",
    "    segments = segmenter(seg_img)\n",
    "    \n",
    "\n",
    "    # Define the labels for the segments we want to include\n",
    "    segment_include = [\"Upper-clothes\", \"Skirt\", \"Pants\", \"Dress\", \"Belt\", \"Bag\", \"Scarf\", \"Left-shoe\", \"Right-shoe\",\"Bag\"]\n",
    "\n",
    "    # # Extend the segments to include additional options if specified\n",
    "    # if additional_option in [\"shoe\"]:\n",
    "    #     segment_include.extend([\"Left-shoe\", \"Right-shoe\"])\n",
    "    # if additional_option in [\"bag\"]:\n",
    "    #     segment_include.extend([\"Bag\"])\n",
    "\n",
    "    # if inverse==False:\n",
    "    #     # Create a list of masks for the included segments\n",
    "    #     mask_list = [np.array(s['mask']) for s in segments if s['label'] in segment_include]\n",
    "    # else:\n",
    "    mask_list = [np.array(s['mask']) for s in segments if s['label'] in segment_include]\n",
    "\n",
    "\n",
    "    # Initialize the final mask with the first mask in the list\n",
    "    final_mask = np.array(mask_list[0])\n",
    "\n",
    "    # Combine all masks into a single final mask\n",
    "    for mask in mask_list:\n",
    "        current_mask = np.array(mask)\n",
    "        final_mask = final_mask + current_mask  # Add the current mask to the final mask\n",
    "\n",
    "    # Create a copy of the final mask for later use\n",
    "    final_array = final_mask.copy()\n",
    "\n",
    "    # Convert the final mask to a PIL Image\n",
    "    final_mask = Image.fromarray(final_mask)\n",
    "    final_mask.save('inv/final_mask_image'+str(j)+'.png')\n",
    "\n",
    "    \n",
    "    # Add the mask as an alpha channel to the original image\n",
    "    seg_img.putalpha(final_mask)\n",
    "    seg_img.save('inv/segmented_image'+str(j)+'.png')\n",
    "    \n",
    "    im2 = final_mask.copy()\n",
    "    seg_img.putalpha(final_mask)\n",
    "    final_mask.paste(seg_img, final_mask)\n",
    "    final_mask.save('inv/black_image'+str(j)+'.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    ".resize(pose.size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modegen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
